# This is an example environment file.
# Copy this file to .env and fill in the values for your setup.

# -----------------------------------------------------------------------------
# RAG Core Settings
# -----------------------------------------------------------------------------

# Embedding model from HuggingFace (SentenceTransformer).
# This model will be downloaded and run locally.
# Recommended Chinese/English model: "shibing624/text2vec-base-chinese"
# Recommended English model: "all-mpnet-base-v2"
EMBEDDING_MODEL_NAME="shibing624/text2vec-base-chinese"

# Path to the folder containing source documents to be ingested.
# This path is relative to the project root.
DOCS_PATH="./data"

# Path to the folder where the FAISS vector store will be saved.
VECTOR_STORE_PATH="./vector_store"


# -----------------------------------------------------------------------------
# LLM Settings (for vLLM)
# -----------------------------------------------------------------------------

# Name or path of the Qwen model to be served by vLLM.
# This should match the model you are serving with your vLLM instance.
# Example: "Qwen/Qwen1.5-7B-Chat"
LLM_MODEL_NAME="Qwen/Qwen1.5-7B-Chat"

# The API base URL for the vLLM OpenAI-compatible server.
# If you run vLLM on a different machine or port, update this URL.
# If you use the provided docker-compose vllm service, this might be http://vllm:8000/v1
VLLM_API_BASE="http://localhost:8000/v1"

# We don't need a real API key for a local vLLM, but the client expects a value.
VLLM_API_KEY="EMPTY"


# -----------------------------------------------------------------------------
# Database Settings
# -----------------------------------------------------------------------------

# SQLAlchemy database URL.
# For SQLite, the path is relative to the project root.
# The default is to create a file named 'app.db' in the root directory.
DATABASE_URL="sqlite:///./app.db"
